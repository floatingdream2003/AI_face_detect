# AI 合成人脸图像检测模型（基于 Swin Transformer 与微光法）

本项目提出了一种基于 Swin Transformer 架构的 AI 合成人脸图像检测方法，**通过鲁棒跨域分类框架 "微光法"**，有效解决了跨域场景下的域偏移、风格差异和噪声干扰等问题，显著提升了模型在复杂场景中的检测性能。

## 模型亮点

- **Swin Transformer 架构**：采用层次化特征映射和移动窗口自注意力机制，高效处理高分辨率人脸图像
- **微光法创新框架**：策略性不平衡训练结合多权重集成决策，增强跨域鲁棒性
- **优异跨域性能**：在域偏移场景下检测准确率较传统方法提升超 30%（如域 C 从 55.3% 提升至 89.2%）
- **广泛适用性**：已在医学图像诊断、工业质检等跨域任务中验证有效性

## 核心技术

### 1. Swin Transformer 架构优势

- **层次化特征提取**：通过 4 个 Stage 构建不同尺度特征图（下采样 4/8/16 倍），适配目标检测与分类任务

- 窗口自注意力机制：

  - W-MSA：在局部窗口内计算自注意力，降低计算复杂度
  - SW-MSA：通过窗口移位实现相邻窗口信息交互

- 高效特征处理流程：

  ```plaintext
  输入图像 → Patch Partition → Linear Embedding → 4个Stage特征提取 → 分类头
  ```

### 2. 微光法（鲁棒跨域分类框架）

- 策略性不平衡训练：

  - 刻意构造 1:10 的类别不平衡训练集（少数类 300 样本，多数类 3000 样本）
  - 通过欠补偿权重设计，提升困难样本识别能力

- 多权重集成决策：

  - 引入可信度阈值 θ，当任意基分类器置信度 >θ 时判定为少数类

  - 集成公式：
    $$
    C_{\text{final}} = 
    \begin{cases} 
    \text{类别1} & \text{若 } \exists w_{i} \in W: P_{w_{i}}(y=1|x)>\theta \\
    \text{类别2} & \text{其他情况}
    \end{cases}
    $$

- 改进的 Focal Loss：

  - 引入样本特征权重因子：
    $$
    \omega(x) = \exp\left(\frac{\|f(x)\|_{2}}{\sigma^{2}}\right)
    $$
    

  - 公式：
    $$
    FL(p_{t}) = -\alpha(1-p_{t})^{\gamma} \log(p_{t}) \cdot \omega(x)
    $$

## 性能表现

### 跨域检测准确率对比

| 方法             | 域 A（标准数据） | 域 B（轻微偏移） | 域 C（噪声 & 风格变化） |
| ---------------- | ---------------- | ---------------- | ----------------------- |
| 基准模型         | 99.2%            | 92.1%            | 55.3%                   |
| 传统迁移学习     | 99.8%            | 98.8%            | 63.7%                   |
| 本模型（微光法） | 99.5%            | 98.8%            | 89.2%                   |

### 典型应用场景提升

- **Deepfake 检测**：非常用生成模型场景下检测率从 63.7%→89.2%
- **医学图像诊断**：不同设备间迁移准确率从 71.2%→82.8%
- **工业质检**：复杂光照环境下检测率从 65.3%→85.1%

# 详细说明见-README.pdf
